# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FDcGuafk8rt6O7JGqBNo7-WMI188R2Wi
"""

import streamlit as st
import joblib
import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

# --- NLTK Stopwords Download ---
# This is done once and then cached.
@st.cache_data
import streamlit as st
import nltk
import ssl

# This is a more robust NLTK download setup
@st.cache_resource
def setup_nltk():
    """Downloads NLTK data and handles potential SSL errors."""
    try:
        # Create an unverified SSL context to bypass certificate issues
        _create_unverified_https_context = ssl._create_unverified_context
    except AttributeError:
        # This is for older Python versions where the attribute doesn't exist.
        pass
    else:
        # Apply the unverified context
        ssl._create_default_https_context = _create_unverified_https_context

    # Now, try to download the necessary NLTK data
    packages = ['punkt', 'stopwords']
    for package in packages:
        try:
            nltk.data.find(f'tokenizers/{package}' if package == 'punkt' else f'corpora/{package}')
        except nltk.downloader.DownloadError:
            st.toast(f'Downloading NLTK package: {package}...', icon='‚è≥')
            nltk.download(package)
            st.toast(f'Downloaded {package}!', icon='‚úÖ')

# Run the setup function at the absolute start of the app
setup_nltk()

# --- Add this code ---
# Function to download NLTK data if not already present
@st.cache_resource

def download_nltk_data():
    nltk.download('punkt')
    nltk.download('stopwords')
    return set(stopwords.words('english'))

stop_words = download_nltk_data()


# --- Load Model and Vectorizer ---
# Use st.cache_resource to load these only once and speed up the app.
@st.cache_resource
def load_model_and_vectorizer():
    """Loads the saved SVM model and TF-IDF vectorizer."""
    try:
        model = joblib.load('tuned_svm_linear_model.pkl')
        vectorizer = joblib.load('vectorizer.pkl')
        return model, vectorizer
    except FileNotFoundError:
        st.error("Model or vectorizer file not found. Please make sure 'tuned_svm_linear_model.pkl' and 'vectorizer.pkl' are in the same directory.")
        return None, None

model, tfidf_vectorizer = load_model_and_vectorizer()


# --- Text Preprocessing Function ---
# This function must be identical to the one used for training.
def preprocess_text(text):
    """Cleans and preprocesses the input text."""
    # 1. Convert to lowercase
    text = text.lower()
    # 2. Remove punctuation and extra spaces
    text = re.sub(r'[^\w\s]', ' ', text)
    text = re.sub(r'\s+', ' ', text).strip()
    # 3. Tokenization
    tokens = word_tokenize(text)
    # 4. Remove stopwords
    tokens = [token for token in tokens if token not in stop_words]
    # 5. Join tokens back to string
    return ' '.join(tokens)


# --- Custom CSS for Styling ---
def local_css(file_name):
    with open(file_name) as f:
        st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)

# You can create a style.css file or embed the style directly
st.markdown("""
<style>
/* Main page background */
.main {
    background-color: #FFFFFF; /* White */
}
/* Title color */
h1 {
    color: #800000; /* Maroon */
}
/* Button style */
.stButton>button {
    background-color: #000080; /* Navy Blue */
    color: white;
    border-radius: 5px;
    border: none;
    padding: 10px 20px;
}
.stButton>button:hover {
    background-color: #800000; /* Maroon on hover */
    color: white;
}
/* Text area style */
.stTextArea textarea {
    border: 2px solid #000080; /* Navy Blue border */
    border-radius: 5px;
}
/* Success box for prediction */
.st-success {
    background-color: rgba(0, 0, 128, 0.1); /* Light Navy Blue */
    border: 1px solid #000080; /* Navy Blue */
    border-radius: 5px;
    color: #800000; /* Maroon text */
}
</style>
""", unsafe_allow_html=True)


# --- Streamlit App Interface ---
st.title('üì∞ BBC News Article Classifier')

st.markdown("""
Enter the text of a news article below, and the model will predict its category:
**Business, Entertainment, Politics, Sport, or Tech.**
""")

# User input text area
user_input = st.text_area("Enter article text here:", height=250)

# Prediction button
if st.button('Classify Article'):
    if model and tfidf_vectorizer:
        if user_input.strip():
            # 1. Preprocess the input
            processed_input = preprocess_text(user_input)

            # 2. Vectorize the processed text
            vectorized_input = tfidf_vectorizer.transform([processed_input])

            # 3. Make a prediction
            prediction = model.predict(vectorized_input)

            # 4. Map prediction to category name
            # This mapping must match the LabelEncoder from your notebook
            category_mapping = {
                0: 'Business',
                1: 'Entertainment',
                2: 'Politics',
                3: 'Sport',
                4: 'Tech'
            }
            predicted_category = category_mapping.get(prediction[0], 'Unknown')

            # 5. Display the result
            st.success(f"**Predicted Category:** {predicted_category}")
        else:
            st.warning("Please enter some text to classify.")
